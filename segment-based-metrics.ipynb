{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This note is the implementation of past research regarding segmentation-based metrics\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import cv2\n",
    "import csv\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from skimage import util, color\n",
    "import math\n",
    "\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.filters import rank\n",
    "from skimage.morphology import  disk\n",
    "from skimage.feature import canny\n",
    "import scipy.spatial as spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "infiles = [\n",
    "#'999*ted.com',\n",
    "'0*theboneandjointcenter.com',\n",
    "#'1*mozilla.org',\n",
    "'2*two-n.com',\n",
    "#'3*segmentfault.com',\n",
    "#'4*makeitok.org',\n",
    "'5*disney.co.jp',\n",
    "'6*wikipedia.org',\n",
    "'7*news.yahoo.co.jp',\n",
    "'8*huxiu.com',\n",
    "#'9*fangdd.com',\n",
    "'10*cheshi.com',\n",
    "'11*humblebundle.com',\n",
    "'12*theatlantic.com',\n",
    "#'13*superprof.fr',\n",
    "'14*microsoft.com',\n",
    "'15*opera.com',\n",
    "'16*labinthewild.org',\n",
    "#'17*nounplus.net',\n",
    "'18*richyli.com',\n",
    "'19*pxtoem.com', \n",
    "#'20*goofy.photo',\n",
    "'21*javadrive.jp',\n",
    "#'22*jcodecraeer.com',\n",
    "#'23*hdpfans.com',\n",
    "'24*jiqimao.tv',\n",
    "'25*clamav.net',\n",
    "'26*bootcdn.cn',\n",
    "'27*runoob.com',\n",
    "'28*tensorfly.cn',\n",
    "'29*journaldugeek.com', \n",
    "'30*matetranslate.com',\n",
    "'31*kameisyouten.ocnk.net',\n",
    "'32*gingerweb.jp',\n",
    "'33*cp.pocky.jp',\n",
    "'34*aladdin-aic.com',\n",
    "#'35*ho-ginza.net',\n",
    "#'36*pandayori.com',\n",
    "#'37*sekimoto.dental',\n",
    "'38*kokage-m.com',\n",
    "#'39*coming-saji.com',\n",
    "#'40*bluewood.bitter.jp',\n",
    "'41*steakland.jp',\n",
    "'42*showroomprive.com',\n",
    "'43*imas-cg.net',\n",
    "'44*filetender.com',\n",
    "'45*hexo.io',\n",
    "'46*yinwang.org',\n",
    "'47*blog.yitianshijie.net',\n",
    "'48*yatani.jp',\n",
    "'49*qiita.com',\n",
    "'50*52nlp.cn',\n",
    "'51*guidetojapanese.org',\n",
    "'52*olderadults.mobi',\n",
    "'53*blog.whatsapp.com',\n",
    "#'54*stratechery.com',\n",
    "'55*lomake.fi',\n",
    "#'56*theclinic.cl',\n",
    "'57*bgmaimuna.com',\n",
    "'58*0dt.net',\n",
    "'59*web.ics.purdue.edu',\n",
    "'60*canon-foundation.jp',\n",
    "#'61*docs.opencv.org',\n",
    "#'62*interaction-design.org',\n",
    "#'63*jlpt.jp',\n",
    "'64*blog.sciencenet.cn',\n",
    "'65*pantone.com',\n",
    "#'66*sdtech.co.jp',\n",
    "'67*news.livedoor.com',\n",
    "'68*gmo.jp',\n",
    "'69*tokai-tv.com', \n",
    "'70*life-is-tech.com',\n",
    "'71*bloomberg.co.jp',\n",
    "'72*cerezo.jp',\n",
    "'73*tech.nikkeibp.co.jp',\n",
    "'74*jp.techcrunch.com',\n",
    "'75*capcom.co.jp',\n",
    "#'76*kenkun-jinja.org',\n",
    "'77*sankei.com',\n",
    "'78*tech-jp.co.jp',\n",
    "'79*tech-camp.in',\n",
    "'80*hasegawa-heart.com',\n",
    "'81*techplay.jp',\n",
    "#'82*ubejinja.or.jp',\n",
    "#'83*19lou.com',\n",
    "#'84*jiankang.com',\n",
    "'85*cps.com.cn',\n",
    "#'86*hea.cn',\n",
    "#'87*jfc.or.jp',\n",
    "'88*trafst.jp',\n",
    "'89*infoq.com',\n",
    "#'90*secure.j-bus.co.jp',\n",
    "'91*jcr.incites.thomsonreuters.com',\n",
    "'92*dna.fr',\n",
    "'93*macg.co',\n",
    "'94*cvpr2018.thecvf.com',\n",
    "'95*chi2019.acm.org',\n",
    "'96*swellnet.com',\n",
    "'97*klex.ru',\n",
    "#'98*kudago.com',\n",
    "'99*theborneopost.com'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_b64_img(b64):\n",
    "    img = base64.b64decode(b64)\n",
    "    npimg = np.fromstring(img, dtype=np.uint8)\n",
    "    return cv2.imdecode(npimg, 1)\n",
    "\n",
    "class BBox(object):\n",
    "    def __init__(self, x1, y1, x2, y2):\n",
    "        # (x1, y1) is the upper left corner,\n",
    "        # (x2, y2) is the lower right corner,  \n",
    "        if x1 > x2: x1, x2 = x2, x1\n",
    "        if y1 > y2: y1, y2 = y2, y1\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "\n",
    "    def taxicab_diagonal(self):\n",
    "        return self.x2 - self.x1 + self.y2 - self.y1\n",
    "\n",
    "    def overlaps(self, other):\n",
    "        # Return True if self and other overlap.        \n",
    "        return not ((self.x1 > other.x2) or (self.x2 < other.x1) or (self.y1 > other.y2) or (self.y2 < other.y1))\n",
    "\n",
    "def makeClassFromCont(contours):\n",
    "    bboxes = []\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w < 5 or h < 5: \n",
    "            continue\n",
    "        bboxes.append(BBox(x, y, x+w, y+h))\n",
    "    return bboxes\n",
    "\n",
    "def remove_overlaps(contours):\n",
    "    #This function returns a set of bboxes after removing the overlapping contours\n",
    "    bboxes = makeClassFromCont(contours)\n",
    "    \n",
    "    corners = []\n",
    "    ulcorners = []\n",
    "\n",
    "    # dict mapping corners to Bboxes.\n",
    "    bbox_map = {}\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        ul = (bbox.x1, bbox.y1)\n",
    "        lr = (bbox.x2, bbox.y2)\n",
    "        bbox_map[ul] = bbox\n",
    "        bbox_map[lr] = bbox\n",
    "        ulcorners.append(ul)\n",
    "        corners.append(ul)\n",
    "        corners.append(lr)        \n",
    "\n",
    "    try:\n",
    "        tree = spatial.KDTree(np.asarray(corners))\n",
    "    except Exception:\n",
    "        return 0\n",
    "    for corner in ulcorners:\n",
    "        bbox = bbox_map[corner]\n",
    "        # Find all points which are within a taxicab distance of corner\n",
    "        indices = tree.query_ball_point(corner, bbox_map[corner].taxicab_diagonal(), p = 1)\n",
    "        for near_corner in tree.data[indices]:\n",
    "            near_bbox = bbox_map[tuple(near_corner)]\n",
    "            if bbox != near_bbox and bbox.overlaps(near_bbox):\n",
    "                # Expand both the bboxes\n",
    "                bbox.x1 = near_bbox.x1 = min(bbox.x1, near_bbox.x1)\n",
    "                bbox.y1 = near_bbox.y1 = min(bbox.y1, near_bbox.y1) \n",
    "                bbox.x2 = near_bbox.x2 = max(bbox.x2, near_bbox.x2)\n",
    "                bbox.y2 = near_bbox.y2 = max(bbox.y2, near_bbox.y2) \n",
    "    return set(bbox_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements(b64, detailed=True, preview=True):\n",
    "    img_bgr = read_b64_img(b64)\n",
    "    img_out = np.copy(img_bgr)\n",
    "\n",
    "    contours_all_v, contours_all_h = segment(img_bgr, h_blur=13, v_blur=9)\n",
    "\n",
    "    thickness = 1\n",
    "    if detailed:\n",
    "        contours_all = contours_all_h\n",
    "    else:\n",
    "        contours_all = contours_all_v\n",
    "        thickness = 2\n",
    "\n",
    "    offset, offset1 = 3, 5\n",
    "\n",
    "    elements = []\n",
    "    N = len(contours_all)\n",
    "    for i, c in zip(range(N), contours_all):\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        if w <= 15:\n",
    "            continue\n",
    "        if h <= 10:\n",
    "            continue\n",
    "\n",
    "        img_out = cv2.rectangle(img_out, (x, y), (x + w, y + h), (0, 0, 255), thickness)\n",
    "\n",
    "        ele_b64 = base64.b64encode(cv2.imencode(\".png\", img_bgr[y:y+h, x:x+w])[1])\n",
    "\n",
    "        elements.append({\n",
    "            \"id\": i,\n",
    "            \"tag\": \"\",\n",
    "            \"x_position\": x,\n",
    "            \"y_position\": y,\n",
    "            \"width\": w,\n",
    "            \"height\": h,\n",
    "            \"b64\": ele_b64\n",
    "        })\n",
    "\n",
    "    result = {\n",
    "        \"elements\": elements\n",
    "    }\n",
    "\n",
    "    if preview:\n",
    "        b64 = base64.b64encode(cv2.imencode(\".png\", img_out)[1])\n",
    "        result[\"preview\"] = b64\n",
    "\n",
    "    return result\n",
    "\n",
    "def segment(img_bgr, h_blur=13, v_blur=9):\n",
    "    BW = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(BW, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    denoised = rank.median(BW, disk(5))\n",
    "    gradient_denoised = rank.gradient(denoised, disk(1))\n",
    "\n",
    "    gradient_0 = rank.gradient(img_bgr[:, :, 0], disk(1))\n",
    "    gradient_1 = rank.gradient(img_bgr[:, :, 1], disk(1))\n",
    "    gradient_2 = rank.gradient(img_bgr[:, :, 2], disk(1))\n",
    "\n",
    "    sobelx64f = cv2.Sobel(BW, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    abs_sobel64f = np.absolute(sobelx64f)\n",
    "    sobel_8u = np.uint8(abs_sobel64f)\n",
    "    img_canny = canny(BW)\n",
    "\n",
    "    _, contours_thresh, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours_0, _ = cv2.findContours(gradient_0, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours_1, _ = cv2.findContours(gradient_1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours_2, _ = cv2.findContours(gradient_2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours_denoised, _ = cv2.findContours(gradient_denoised, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours_sobel, _ = cv2.findContours(sobel_8u, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours_canny, _ = cv2.findContours(img_as_ubyte(img_canny), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    contours = contours_0 + contours_1 + contours_2 + contours_denoised + contours_sobel + contours_canny\n",
    "\n",
    "    # bbox = utils.remove_overlaps(contours)\n",
    "    bbox = 0 # No big bounding box\n",
    "\n",
    "    temp = np.zeros_like(BW)\n",
    "\n",
    "    if bbox != 0:\n",
    "        for bb in bbox:\n",
    "            temp = cv2.rectangle(temp, (bb.x1, bb.y1), (bb.x2, bb.y2), (255, 255, 255), 1)\n",
    "\n",
    "    for c in contours_thresh:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        temp = cv2.rectangle(temp, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
    "\n",
    "    # Horizontal Blurring filter\n",
    "    size = h_blur # 11\n",
    "    kmb = np.zeros((size, size))\n",
    "    kmb[int(size / 2), :] = np.ones(size)\n",
    "    kmb = kmb/size\n",
    "\n",
    "    # Apply horizontal blurring here\n",
    "    temp = cv2.filter2D(temp, -1, kmb)\n",
    "    _, contours_all_h, _ = cv2.findContours(temp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Vertical Blurring filter\n",
    "    size = v_blur # 13\n",
    "    kmb = np.zeros((size, size))\n",
    "    kmb[:, int(size / 2)] = np.ones(size)\n",
    "    kmb = kmb/size\n",
    "\n",
    "    # Apply vertical blurring here\n",
    "    temp = cv2.filter2D(temp, -1, kmb)\n",
    "    _, contours_all_v, _ = cv2.findContours(temp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    return contours_all_v, contours_all_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSegmentation(object):\n",
    "    def setUp(self, b64):\n",
    "        self.elements = get_elements(b64, detailed=True)\n",
    "        \n",
    "        #self.elements = segmentation.get_elements(test_data.load_test_data(), detailed=False)\n",
    "        \n",
    "    def test_returns_list(self):\n",
    "        self.assertTrue(isinstance(self.elements, list))\n",
    "\n",
    "    def test_list_contains_dicts(self):\n",
    "        for element in self.elements: \n",
    "            self.assertTrue(isinstance(element, dict))\n",
    "\n",
    "    def test_elements_are_valid(self):\n",
    "        for element in self.elements:\n",
    "            self.assertTrue('id' in element)\n",
    "            self.assertTrue('tag' in element)\n",
    "            self.assertTrue('x_position' in element)\n",
    "            self.assertTrue('y_position' in element)\n",
    "            self.assertTrue('width' in element)\n",
    "            self.assertTrue('height' in element)\n",
    "\n",
    "            self.assertTrue(isinstance(element['id'], int))\n",
    "            self.assertTrue(isinstance(element['tag'], basestring))\n",
    "            self.assertTrue(isinstance(element['x_position'], int))\n",
    "            self.assertTrue(isinstance(element['y_position'], int))\n",
    "            self.assertTrue(isinstance(element['width'], int))\n",
    "            self.assertTrue(isinstance(element['height'], int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_space(b64, elements):    \n",
    "    b64 = base64.b64decode(b64)\n",
    "    b64 = BytesIO(b64)\n",
    "    img = Image.open(b64)\n",
    "\n",
    "    width, height = img.size\n",
    "\n",
    "    imsize = width * height\n",
    "\n",
    "    non_white_space = 0\n",
    "    for ele in elements:\n",
    "        type(ele['width'])\n",
    "        non_white_space += ele['width'] * ele['height']\n",
    "\n",
    "    return (imsize - non_white_space) / float(imsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_quality(b64, seg_elements):\n",
    "    # Calculating the number of elements\n",
    "    num_element = len(seg_elements)\n",
    "\n",
    "    # Converting json file to the python's dictionary format\n",
    "    data_dict = {'pos_X': [0 for _ in range(num_element)], 'pos_Y': [0 for _ in range(num_element)], 'Shapes_W': [0 for _ in range(num_element)], 'Shapes_H': [0 for _ in range(num_element)]}\n",
    "    for i in range(num_element):\n",
    "        data_dict['pos_X'][i] = seg_elements[i][\"x_position\"]\n",
    "        data_dict['pos_Y'][i] = seg_elements[i][\"y_position\"]\n",
    "        data_dict['Shapes_W'][i] = seg_elements[i][\"width\"]\n",
    "        data_dict['Shapes_H'][i] = seg_elements[i][\"height\"]\n",
    "\n",
    "    # A function to return the number of alignment lines in one dimension\n",
    "    def alignment(dna1, dna2):\n",
    "        data = dna1 + dna2\n",
    "\n",
    "        # Calculating the number of elements\n",
    "        align = len(set(data))\n",
    "\n",
    "        return align\n",
    "\n",
    "\n",
    "    # Finding end point of each element\n",
    "    end_x = [0 for _ in range(num_element)]\n",
    "    end_y = [0 for _ in range(num_element)]\n",
    "    for i in range(num_element):\n",
    "        end_x[i] = np.sum([data_dict['pos_X'][i], data_dict['Shapes_W'][i]], axis=0)\n",
    "        end_y[i] = np.sum([data_dict['pos_Y'][i], data_dict['Shapes_H'][i]], axis=0)\n",
    "\n",
    "    # Calculating the number of alignment lines based on the  and horizontally\n",
    "    num_align_x = alignment(data_dict['pos_X'], end_x)\n",
    "    num_align_y = alignment(data_dict['pos_Y'], end_y)\n",
    "\n",
    "    # Total number of alignment lines\n",
    "    fit_align = sum([num_align_x, num_align_y])\n",
    "\n",
    "    return fit_align\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_space_list = []\n",
    "grid_quality_list = []\n",
    "\n",
    "def main():\n",
    "    for i in infiles:\n",
    "        no, title = i.split('*')\n",
    "        with open('webpages/'+ title +'.png', 'rb') as f:\n",
    "            im = f.read()\n",
    "            b64 = base64.b64encode(im)\n",
    "            ts = TestSegmentation()\n",
    "            ts.setUp(b64)\n",
    "            \n",
    "        result = grid_quality(b64, ts.elements['elements'])\n",
    "        \n",
    "        thisItem = [title, result]\n",
    "        print(thisItem)\n",
    "        \n",
    "        grid_quality_list.append(thisItem)\n",
    "\n",
    "    with open('grid_quality.csv', 'w') as  f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['title', 'grid_quality'])\n",
    "        writer.writerows(grid_quality_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['theboneandjointcenter.com', 71]\n",
      "['two-n.com', 141]\n",
      "['disney.co.jp', 94]\n",
      "['wikipedia.org', 141]\n",
      "['news.yahoo.co.jp', 182]\n",
      "['huxiu.com', 159]\n",
      "['cheshi.com', 251]\n",
      "['humblebundle.com', 53]\n",
      "['theatlantic.com', 122]\n",
      "['microsoft.com', 55]\n",
      "['opera.com', 75]\n",
      "['labinthewild.org', 146]\n",
      "['richyli.com', 98]\n",
      "['pxtoem.com', 8]\n",
      "['javadrive.jp', 128]\n",
      "['jiqimao.tv', 167]\n",
      "['clamav.net', 54]\n",
      "['bootcdn.cn', 54]\n",
      "['runoob.com', 145]\n",
      "['tensorfly.cn', 57]\n",
      "['journaldugeek.com', 108]\n",
      "['matetranslate.com', 42]\n",
      "['kameisyouten.ocnk.net', 113]\n",
      "['gingerweb.jp', 59]\n",
      "['cp.pocky.jp', 68]\n",
      "['aladdin-aic.com', 115]\n",
      "['kokage-m.com', 154]\n",
      "['steakland.jp', 4]\n",
      "['showroomprive.com', 71]\n",
      "['imas-cg.net', 56]\n",
      "['filetender.com', 100]\n",
      "['hexo.io', 50]\n",
      "['yinwang.org', 56]\n",
      "['blog.yitianshijie.net', 98]\n",
      "['yatani.jp', 98]\n",
      "['qiita.com', 62]\n",
      "['52nlp.cn', 126]\n",
      "['guidetojapanese.org', 61]\n",
      "['olderadults.mobi', 95]\n",
      "['blog.whatsapp.com', 58]\n",
      "['lomake.fi', 65]\n",
      "['bgmaimuna.com', 129]\n",
      "['0dt.net', 103]\n",
      "['web.ics.purdue.edu', 17]\n",
      "['canon-foundation.jp', 88]\n",
      "['blog.sciencenet.cn', 321]\n",
      "['pantone.com', 126]\n",
      "['news.livedoor.com', 226]\n",
      "['gmo.jp', 134]\n",
      "['tokai-tv.com', 124]\n",
      "['life-is-tech.com', 45]\n",
      "['bloomberg.co.jp', 81]\n",
      "['cerezo.jp', 11]\n",
      "['tech.nikkeibp.co.jp', 199]\n",
      "['jp.techcrunch.com', 98]\n",
      "['capcom.co.jp', 103]\n",
      "['sankei.com', 151]\n",
      "['tech-jp.co.jp', 57]\n",
      "['tech-camp.in', 57]\n",
      "['hasegawa-heart.com', 79]\n",
      "['techplay.jp', 71]\n",
      "['cps.com.cn', 176]\n",
      "['trafst.jp', 179]\n",
      "['infoq.com', 250]\n",
      "['jcr.incites.thomsonreuters.com', 53]\n",
      "['dna.fr', 100]\n",
      "['macg.co', 88]\n",
      "['cvpr2018.thecvf.com', 80]\n",
      "['chi2019.acm.org', 160]\n",
      "['swellnet.com', 68]\n",
      "['klex.ru', 82]\n",
      "['theborneopost.com', 106]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
